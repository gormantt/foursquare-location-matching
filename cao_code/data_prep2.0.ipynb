{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1615dd0-25af-4e2c-bcdb-d6598d5a1488",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "What we do in this notebook:\n",
    "\n",
    "#### Loading\n",
    "* Read data from the Kaggle file `pairs.csv`.\n",
    "* Take the subset of data with `df.country_1==\"US\"` and `df.country_2==\"US\"`.\n",
    "\n",
    "#### Cleaning\n",
    "* Replace missing string values with the empty string. (There is no missing values in the coordinates data.)\n",
    "* Unify the `state` code into two letter format using the state code file `state-code.csv`.\n",
    "* Throw away rows with the `state` codes that are not in `state-code.csv`.\n",
    "\n",
    "#### Adding features\n",
    "* For each pairs of feature in `[('latitude','longitude'),'name','address','city','state','zip','url','phone','categories']`.\n",
    "  calculate the \"difference\" using two different metrics: \n",
    "     * straight line distance, great circle distance for ('latitude','longitude')\n",
    "     * SequenceMatcher, Levinshtein, Cosine-similarity for other features\n",
    "     \n",
    "* Add a new column with name, depending on the metric used, in the following formats\n",
    "    * `geo_diff` (straight line distance for ('latitude','longitude'))\n",
    "    * `geo_theta_diff` (great circle distance for ('latitude','longitude'))\n",
    "    * `<feature>_diff_seq`\n",
    "    * `<feature>_diff_lev`\n",
    "    * `<feature>_csim`\n",
    "* Save the new dataframe into the file `pairs_us_diffs.csv`. Current size: 60M.\n",
    "* At the end, we just take a very quick look at the corelation matrix of those \"difference features\".\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c83a8f-4c63-40e7-9745-006d8e2ba430",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551463c2-f250-4fad-8fed-7d4644b43666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731ad6aa-9670-4708-bd10-7b8ec1fa54f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from pairs.csv\n",
    "# replace mypath to your local path of the file pairs.csv\n",
    "mypath = \"./data-foursquare-location-matching/pairs.csv\"\n",
    "df_pairs  = pd.read_csv(mypath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624b964c-d184-4830-b515-68994a98c326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider only the US pairs\n",
    "df_pairs_us = df_pairs[(df_pairs.country_1=='US') & (df_pairs.country_2=='US')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f4d6cf-b5af-4215-99c7-96c88013d40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_pairs_us.copy()\n",
    "# reindexing the subset.\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a7d6cf-b757-40fd-977b-2e19fadedf3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fill missing value with empty string.\n",
    "df.fillna('', inplace=True)\n",
    "# df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8195957-ae4e-400a-a85e-91e3291279f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string\n",
    "string_features = ['name_1', 'name_2',\n",
    "                   'address_1', 'address_2', \n",
    "                   'city_1', 'city_2',\n",
    "                   'state_1', 'state_2', \n",
    "                   'zip_1', 'zip_2',\n",
    "                   'country_1', 'country_2', \n",
    "                   'url_1', 'url_2',\n",
    "                   'phone_1', 'phone_2', \n",
    "                   'categories_1', 'categories_2']\n",
    "position_features = ['latitude_1', 'latitude_2', 'longitude_1', 'longitude_2']\n",
    "\n",
    "df[string_features] = df[string_features].fillna('').astype(str).apply(\n",
    "    lambda x: x.str.lower().str.replace('[{}]'.format(string.punctuation),'',regex=True))\n",
    "df[position_features] = df[position_features].astype('float64')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c14ac71-9402-42a9-9d5d-43970680eb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two letter US state code from \n",
    "# https://www.bls.gov/respondents/mwr/electronic-data-interchange/appendix-d-usps-state-abbreviations-and-fips-codes.htm\n",
    "# saved in state-code.csv\n",
    "# Notes: Don't be confused with FIPS Code: 56 is not the total; some numbers are missing.\n",
    "\n",
    "state = pd.read_csv('./data/state-code.csv', header=None)\n",
    "state.columns=['state','code']\n",
    "state['state'] = state['state'].str.upper()\n",
    "state.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0913c616-cf46-426c-8831-a82d34f1d79e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Unify the format of the state code\n",
    "\n",
    "dict_lookup = dict(zip(state['state'],state['code']))\n",
    "dict_lookup['CALIF']  = 'CA'\n",
    "# dict_lookup['D.C.']   = 'DC'\n",
    "dict_lookup['ONNY']  = 'NY'\n",
    "\n",
    "df['state_1'] = df['state_1'].str.upper()\n",
    "df['state_2'] = df['state_2'].str.upper()\n",
    "\n",
    "for x in dict_lookup.keys():\n",
    "    \n",
    "    df.loc[df[\"state_1\"] == x, \"state_1\"] = dict_lookup[x]\n",
    "    df.loc[df[\"state_2\"] == x, \"state_2\"] = dict_lookup[x]\n",
    "    \n",
    "print(df['state_1'].unique())\n",
    "print(df['state_2'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9989e97c-1457-4a16-8286-266f0885d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(df['state_1'].unique()).difference(set(state['code'])))\n",
    "print(set(df['state_2'].unique()).difference(set(state['code'])))\n",
    "S1 = set(df['state_1'].unique())\n",
    "S2 = set(df['state_2'].unique())\n",
    "S  = set(state['code'])\n",
    "drop_list = S1.union(S2).difference(S)\n",
    "print(drop_list)\n",
    "drop_list.remove('')\n",
    "print(drop_list) # drop_list = ['UK', 'CE', 'NU', '国外']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d55e001-9a98-4943-bc1d-483cff6179a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If your data frame does not have the same number of rows, \n",
    "# it is very likely because Yu Cao throw away \"fake\" us data\n",
    "# as follows. Comment out the following lines if you want to keep those rows.\n",
    "\n",
    "df = df[df['state_1'].isin(drop_list)==False] \n",
    "df = df[df['state_2'].isin(drop_list)==False] \n",
    "print(df['state_1'].unique())\n",
    "print(df['state_2'].unique())\n",
    "tmp1 = df['state_1'].unique()\n",
    "tmp2 = df['state_2'].unique()\n",
    "print(set(state['code']).difference(set(tmp1)))\n",
    "print(set(state['code']).difference(set(tmp2)))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ed0963-19d6-4a3c-8da4-cbfe504edb2c",
   "metadata": {},
   "source": [
    "# Computing \"difference/similarity\" of various features and adding the difference as new columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d7455c-4464-46f3-936e-8a7627051b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diff(df,func,*feature,name=None,sim=None):\n",
    "    '''Get difference of given feature using input metric\n",
    "    \n",
    "    df:      data frame of pairs\n",
    "    func:    metric to apply\n",
    "    feature: features to compare with the metric\n",
    "    name:    new feature name\n",
    "    \n",
    "    '''\n",
    "    if name is None:\n",
    "        name = feature[0]+'_diff'\n",
    "    if sim is None:\n",
    "        sim = 'difference'\n",
    "    else:\n",
    "        sim = 'similarity'\n",
    "    \n",
    "    print('Getting {} in {} with the \"{}\" metric.'.format(sim,feature,func.__name__))\n",
    "    \n",
    "    print('Making new column \"{}\"'.format(name))\n",
    "    print()\n",
    "    cols = [str(x)+'_1' for x in feature]+[str(x)+'_2' for x in feature]   \n",
    "    df[name] = df[cols].apply(func, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fae3e3-7213-4b35-8c04-3eb8aa282da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_metric(pair):\n",
    "    ''' Euclidean distance (l2) for comparing geographic coordinates\n",
    "    \n",
    "    '''\n",
    "    a = np.asarray(pair[0],pair[1])\n",
    "    b = np.asarray(pair[2],pair[3])\n",
    "    return np.linalg.norm(a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea46ccdf-d0f3-43b3-8ad7-7f03e5b64e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "def seq_metric(pair):\n",
    "    ''' metric for comparing strings\n",
    "    \n",
    "    '''\n",
    "    a,b = tuple(pair)\n",
    "    if type(a)!=str or type(b)!=str:\n",
    "        return -1\n",
    "    else:\n",
    "        # from Ling.\n",
    "        a = a.lower().replace(\" \", \"\").replace(\"'\", \"\")\n",
    "        b = b.lower().replace(\" \", \"\").replace(\"'\", \"\")\n",
    "        # b = b.lower().replace('[{}]'.format(string.punctuation),'').replace(\" \", \"\")\n",
    "    return 1-SequenceMatcher(None, a, b).ratio()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4b85a8-55ea-400f-9c2a-13b72250c368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance as lev\n",
    "def lev_metric(pair):\n",
    "    ''' Levenshtein metric for comparing strings\n",
    "    \n",
    "    '''\n",
    "    a,b = tuple(pair)\n",
    "    if type(a)!=str or type(b)!=str:\n",
    "        return -1\n",
    "    elif len(a)==0 or len(b)==0:\n",
    "        return -1\n",
    "    else:\n",
    "        a = a.lower().replace(\" \", \"\").replace(\"'\", \"\")\n",
    "        b = b.lower().replace(\" \", \"\").replace(\"'\", \"\")\n",
    "    return lev(a,b)/max(len(a),len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b97c905-be4f-44c2-8b8e-cf06121c0aa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df.columns.values)\n",
    "print()\n",
    "\n",
    "feature = ('latitude','longitude')\n",
    "get_diff(df,l2_metric,*feature,name='geo_diff')\n",
    "\n",
    "features = ['name','address','city','state','zip','url','phone','categories']\n",
    "features = [[x] for x in features]\n",
    "for feature in features:\n",
    "    get_diff(df,seq_metric,*feature,name=feature[0]+'_diff_seq')\n",
    "    get_diff(df,lev_metric,*feature,name=feature[0]+'_diff_lev')\n",
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351e3e80-5712-4f83-beb7-fb97698fe4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def theta_diff(pair):\n",
    "    ''' Great circle distance for geographic coordinates\n",
    "    \n",
    "    https://en.wikipedia.org/wiki/Great-circle_distance#Computational_formulas\n",
    "    \n",
    "    '''\n",
    "    PI = np.pi\n",
    "    \n",
    "    phi_1, phi_2 = pair[0], pair[1] #latitudes\n",
    "    lam_1, lam_2 = pair[2], pair[3] #longitudes\n",
    "    \n",
    "    # convert to radians for calculation:\n",
    "    for x in [phi_1,phi_2,lam_1,lam_2]:\n",
    "        x = np.deg2rad(x)\n",
    "    \n",
    "    del_lam = lam_1 - lam_2\n",
    "    \n",
    "    p = np.cos(phi_2)*np.sin(del_lam)\n",
    "    q = np.cos(phi_1)*np.sin(phi_2) - np.sin(phi_1)*np.cos(phi_2)*np.cos(del_lam)\n",
    "    r = np.sin(phi_1)*np.sin(phi_2) + np.cos(phi_1)*np.cos(phi_2)*np.cos(del_lam)\n",
    "    \n",
    "    diff = np.arctan(np.sqrt(p**2+q**2)/r)\n",
    "    \n",
    "    return np.abs(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34123eaa-cd91-47eb-a9de-a78ae76d5784",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = ('latitude','longitude')\n",
    "get_diff(df,theta_diff,*feature,name='geo_theta_diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b69b82d-5172-4f68-a3cb-9660cbb63b38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import string\n",
    "\n",
    "def cos_sim(pair):\n",
    "    ''' cosine_sim metric for comparing strings\n",
    "    \n",
    "    '''\n",
    "    a,b = tuple(pair)\n",
    "\n",
    "    try:\n",
    "        if (a == '') | (b == ''):\n",
    "            csim = -1\n",
    "        elif (a == ' ') | (b == ' '):\n",
    "            csim = -1\n",
    "        else:\n",
    "            csim = cosine_similarity(CountVectorizer().fit_transform([a,b]).toarray())[0][1]\n",
    "        return csim\n",
    "    except ValueError:\n",
    "        print(a,b)\n",
    "        csim = -1\n",
    "        return csim\n",
    "    \n",
    "features = ['name','address','city','state','zip','url','phone','categories']\n",
    "features = [[x] for x in features]\n",
    "for feature in features:\n",
    "    get_diff(df,cos_sim,*feature,name=feature[0]+'_csim')\n",
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17273e8e-fa16-4493-9549-26014b12f33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/pairs_us_diffs.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34137a6-046b-4414-af2c-b8860712bf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show size of the file\n",
    "%ls -lh ./data/pairs_us_diffs.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb5288b-2df2-40d6-bfa5-5236f1b0932c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403ff766-da44-40f1-8c66-c07924ba6c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "sns.heatmap(df.iloc[:,-9:].corr(), annot=True, ax=ax)\n",
    "ax.tick_params(axis='both',labelsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8279b6da-4df3-4220-984d-2c49cbe71829",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "sns.heatmap(df.iloc[:,-26:-9:2].corr(), annot=True, ax=ax)\n",
    "ax.tick_params(axis='both',labelsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0365f0af-b927-4ed2-89be-1251971e4e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "sns.heatmap(df.iloc[:,-25:-10:2].corr(), annot=True, ax=ax)\n",
    "ax.tick_params(axis='both',labelsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc4cd75-2b49-45f4-8638-53eb4a80fe69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geo_env]",
   "language": "python",
   "name": "conda-env-geo_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
