{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: Tim Gorman, Yu Cao, Ling Zhou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "# from googletrans import Translator, constants\n",
    "import seaborn as sns\n",
    "import langdetect\n",
    "from langdetect import detect\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from geopandas import GeoDataFrame\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: To install geopandas, open a terminal in jupyter and run the following commands\n",
    "\n",
    "pip install pipwin <br>\n",
    "pipwin install gdal <br>\n",
    "pipwin install fiona <br>\n",
    "pip install geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Exploring train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train  = pd.read_csv(\"../../data_raw/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values in the train set\n",
    "- Every row has the features: `id`, `latitude`, `longitude`, `point_of_interest`\n",
    "- Other features have missing values\n",
    "- Features that have less missing values: `name`, `country`, `categories`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the missing values\n",
    "missing = df_train.isna().sum()/df_train.shape[0]*100\n",
    "missing.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the percentages of missing values for each feature\n",
    "import matplotlib.ticker as mtick\n",
    "tmp = df_train.drop(columns=['id','latitude','longitude','point_of_interest']).isna().sum().sort_values()\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.barh(tmp.index, tmp/len(df_train)*100)\n",
    "ax.set_title(\"(Most) missing values (percentages)\", fontsize=18)\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "ax.tick_params(axis='both', labelsize=15 )\n",
    "ax.set_ylabel('features', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the stupid outliers\n",
    "df_train[df_train['country'].isna()].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the stupid outliers\n",
    "df_train[df_train['name'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `id` feature is unique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train['id'].unique()) == len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of (unique) POIs : {:8d}'.format(len(df_train['point_of_interest'].unique())))\n",
    "print('Number of (unique) ids  : {:8d}'.format(len(df_train['id'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes on the `point_of_interest` feature:\n",
    "\n",
    "https://www.kaggle.com/competitions/foursquare-location-matching/discussion/318967#1783581"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_train['country'] == 'US')\n",
    "print(len(df_train[df_train['zip'].isna()  & mask]))\n",
    "print(len(df_train[df_train['state'].isna()& mask]))\n",
    "print(len(df_train[df_train['city'].isna() & mask]))\n",
    "print(len(df_train[df_train['zip'].isna() & df_train['state'].isna() & df_train['city'].isna() & mask]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latitude and longitude\n",
    "Data concentrate on the US and the Europe: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(40,25))\n",
    "ax.scatter(df_train['longitude'],df_train['latitude'])\n",
    "ax.set_xlabel('longitude',fontsize=40)\n",
    "ax.set_ylabel('latitude',fontsize=40)\n",
    "ax.tick_params(axis='both', labelsize=40)\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = [Point(xy) for xy in zip(df_train['longitude'], df_train['latitude'])]\n",
    "gdf = GeoDataFrame(df_train.copy(), geometry=geometry)   \n",
    "\n",
    "#this is a simple map that goes with geopandas\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "ax = gdf.plot(ax=world.plot(figsize=(20, 12)), marker='o', color='red', markersize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Many Languages are Present?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = []\n",
    "name_data = df_train['name'].sample(10000).fillna('').str.replace('[{}]'.format(string.punctuation),'').str.lower()\n",
    "for item in name_data:\n",
    "    try:\n",
    "        if item != '':\n",
    "            languages.append(detect(item))\n",
    "        pass\n",
    "    except langdetect.LangDetectException as e:\n",
    "        print(item)\n",
    "        continue\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.countplot(x = languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages.count('en')/len(languages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So roughly 20% of the sampled data is in english"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Availability of data by country\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_stats = df_train['country'].value_counts()*100/df_train['country'].value_counts().sum()\n",
    "country_stats = country_stats.head(10).sort_values()\n",
    "country_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "color = [\"gray\"]*len(country_stats.index)\n",
    "color[-1] = \"red\"\n",
    "country_stats.plot(kind = 'barh', ax = ax, color = color)\n",
    "\n",
    "ax.set_title(\"% Available Data by Countries\")\n",
    "ax.set_ylabel('country')\n",
    "ax.set_xlabel('Percentage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The US data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us = df_train[df_train['country']=='US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(40,10))\n",
    "ax.scatter(df_us['longitude'],df_us['latitude'])\n",
    "ax.set_xlabel('longitude',fontsize=40)\n",
    "ax.set_ylabel('latitude',fontsize=40)\n",
    "ax.tick_params(axis='both', labelsize=40)\n",
    "ax.set_title('US data',fontsize=40)\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us[df_us['longitude']>-50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploring and Manipulating pairs.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Pairs Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pd.read_csv(r'C:\\Users\\gorma\\OneDrive\\Documents\\Erdos\\foursquare-location-matching\\data_raw\\pairs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "languages = []\n",
    "for item in pairs['name_1'][0:92]:\n",
    "    if item == pairs['name_1'][92]:\n",
    "        print(item)\n",
    "    languages.append(detect(item))\n",
    "    \n",
    "plt.figure(figsize=(12,8))\n",
    "sns.countplot(x = srcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling NAs and  Making Combined Full Addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs['categories_1'] = pairs['categories_1'].fillna('')\n",
    "pairs['categories_2'] = pairs['categories_2'].fillna('')\n",
    "pairs['full_address_1'] = pairs['address_1'].fillna('') + ' ' + pairs['city_1'].fillna('') + ' ' + pairs['state_1'].fillna('') + ' ' + pairs['zip_1'].fillna('')  + ' ' + pairs['country_1'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs['full_address_1'] = pairs['address_1'].fillna('') + ' ' + pairs['city_1'].fillna('') + ' ' + pairs['state_1'].fillna('') + ' ' + pairs['zip_1'].fillna('')  + ' ' + pairs['country_1'].fillna('')\n",
    "pairs['full_address_2'] = pairs['address_2'].fillna('') + ' ' + pairs['city_2'].fillna('') + ' ' + pairs['state_2'].fillna('') + ' ' + pairs['zip_2'].fillna('')  + ' ' + pairs['country_2'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing to only columns that seems useful. (mostly based on shear amount of nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = ['id_1','name_1', 'latitude_1', 'longitude_1', 'country_1', 'full_address_1', 'categories_1', 'id_2','name_2', 'latitude_2', 'longitude_2', 'country_2', 'full_address_2', 'categories_2', 'match']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_reduced = pairs[column_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_reduced.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating angular difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairs_reduced['theta_diff'] = np.arccos(np.sin(np.radians(pairs_reduced['latitude_1']))*np.sin(np.radians(pairs_reduced['latitude_2']))+\n",
    "#                                        np.cos(np.radians(pairs_reduced['latitude_1']))*np.cos(np.radians(pairs_reduced['latitude_2']))*\n",
    "#                                         np.cos(np.radians(pairs_reduced['longitude_1']-pairs_reduced['longitude_2']))\n",
    "#                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_reduced['theta_diff'] = np.abs(np.arctan(np.sqrt(\n",
    "    (np.cos(np.radians(pairs_reduced['latitude_2']))*np.sin(np.radians(pairs_reduced['longitude_1']-pairs_reduced['longitude_2'])))**2 +\n",
    "        (np.cos(np.radians(pairs_reduced['latitude_1']))*np.sin(np.radians(pairs_reduced['latitude_2']))-\n",
    "            np.sin(np.radians(pairs_reduced['latitude_1']))*np.cos(np.radians(pairs_reduced['latitude_2']))*np.cos(np.radians(pairs_reduced['longitude_1']-pairs_reduced['longitude_2'])))**2\n",
    "                                                )/\n",
    "    (np.sin(np.radians(pairs_reduced['latitude_1']))*np.sin(np.radians(pairs_reduced['latitude_2']))+\n",
    "        np.cos(np.radians(pairs_reduced['latitude_1']))*np.cos(np.radians(pairs_reduced['latitude_2']))*np.cos(np.radians(pairs_reduced['longitude_1']-pairs_reduced['longitude_2']))\n",
    "    )\n",
    "                                               )\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairs_reduced['theta_diff'] = np.sqrt((np.radians(pairs_reduced['longitude_1'])-np.radians(pairs_reduced['longitude_2'])*np.cos(np.radians(pairs_reduced['latitude_1'])))**2 +\n",
    "#         (np.radians(pairs_reduced['latitude_1'])-np.radians(pairs_reduced['latitude_2']))**2\n",
    "#        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairs_reduced['theta_diff'] = (np.radians(pairs_reduced['longitude_1'])-np.radians(pairs_reduced['longitude_2']))**2 + (np.radians(pairs_reduced['latitude_1'])-np.radians(pairs_reduced['latitude_2']))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_reduced[pairs_reduced['theta_diff'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing to only US data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pairs_reduced[(pairs_reduced['country_1'] == 'US') & (pairs_reduced['country_1'] == 'US')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping no longer needed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_red_us = pairs_reduced[(pairs_reduced['country_1'] == 'US') & (pairs_reduced['country_1'] == 'US')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_red_us = pairs_red_us.drop(['country_1','country_2', 'latitude_1', 'longitude_1', 'latitude_2', 'longitude_2'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_red_us.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's probably in my best interest to lower case all of the strings when doing the string matching aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_red_us['name_1'] = pairs_red_us['name_1'].astype(str)\n",
    "pairs_red_us['name_2'] = pairs_red_us['name_2'].astype(str)\n",
    "pairs_red_us['full_address_1'] = pairs_red_us['full_address_1'].astype(str)\n",
    "pairs_red_us['full_address_2'] = pairs_red_us['full_address_2'].astype(str)\n",
    "pairs_red_us['categories_1'] = pairs_red_us['categories_1'].astype(str)\n",
    "pairs_red_us['categories_2'] = pairs_red_us['categories_2'].astype(str)\n",
    "\n",
    "pairs_red_us['name_1'] = pairs_red_us['name_1'].str.lower()\n",
    "pairs_red_us['full_address_1'] = pairs_red_us['full_address_1'].str.lower()\n",
    "pairs_red_us['categories_1'] = pairs_red_us['categories_1'].str.lower()\n",
    "pairs_red_us['name_2'] = pairs_red_us['name_2'].str.lower()\n",
    "pairs_red_us['full_address_2'] = pairs_red_us['full_address_2'].str.lower()\n",
    "pairs_red_us['categories_2'] = pairs_red_us['categories_2'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_red_us.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tihnk I can drop ids as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_red_us = pairs_red_us.drop(['id_1', 'id_2'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pairs_red_us['name_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pairs_red_us['name_1'][pairs_red_us['name_1'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pairs_red_us['name_1'].tolist()[1:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now following the article \"Calculating STring Similarity in Python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_red_us['name_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_red_us['name_1'] = pairs_red_us['name_1'].str.replace('[{}]'.format(string.punctuation),'')\n",
    "pairs_red_us['name_2'] = pairs_red_us['name_2'].str.replace('[{}]'.format(string.punctuation),'')\n",
    "pairs_red_us['full_address_1'] = pairs_red_us['full_address_1'].str.replace('[{}]'.format(string.punctuation),'')\n",
    "pairs_red_us['full_address_2'] = pairs_red_us['full_address_2'].str.replace('[{}]'.format(string.punctuation),'')\n",
    "pairs_red_us['categories_1'] = pairs_red_us['categories_1'].str.replace('[{}]'.format(string.punctuation),'')\n",
    "pairs_red_us['categories_2'] = pairs_red_us['categories_2'].str.replace('[{}]'.format(string.punctuation),'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_red_us['name_1'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_red_us.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_red_us = pairs_red_us.reset_index().drop('index', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_red_us.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_red_us.to_csv(r'C:\\Users\\gorma\\OneDrive\\Documents\\Erdos\\foursquare-location-matching\\tim_code\\working_data\\pairs_reduced_us.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = CountVectorizer().fit_transform([pairs_red_us['name_1'].iloc[0], pairs_red_us['name_2'].iloc[0]]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csim = cosine_similarity(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csim[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(len(pairs_red_us.iloc[:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_cosines = []\n",
    "for i in range(len(pairs_red_us)):\n",
    "    if (pairs_red_us['name_1'].iloc[i] == '') | (pairs_red_us['name_2'].iloc[i] == ''):\n",
    "        csim = -1\n",
    "    else:\n",
    "        csim = cosine_similarity(CountVectorizer().fit_transform([pairs_red_us['name_1'].iloc[i], pairs_red_us['name_2'].iloc[i]]).toarray())[0][1]\n",
    "    name_cosines.append(csim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(name_cosines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_red_us['name_cosines'] = pd.DataFrame(name_cosines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_red_us.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_red_us[pairs_red_us['name_cosines'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_red_us[pairs_red_us['categories_2'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_red_us.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_cosines = []\n",
    "for i in range(len(pairs_red_us)):\n",
    "    if (pairs_red_us['full_address_1'].iloc[i] == '') | (pairs_red_us['full_address_2'].iloc[i] == ''):\n",
    "        csim = -1\n",
    "    else:\n",
    "        csim = cosine_similarity(CountVectorizer().fit_transform([pairs_red_us['full_address_1'].iloc[i], pairs_red_us['full_address_2'].iloc[i]]).toarray())[0][1]\n",
    "    address_cosines.append(csim)\n",
    "\n",
    "pairs_red_us['full_address_cosines'] = pd.DataFrame(address_cosines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_red_us.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_cosines = []\n",
    "for i in range(len(pairs_red_us)):\n",
    "    if (pairs_red_us['categories_1'].iloc[i] == '') | (pairs_red_us['categories_2'].iloc[i] == ''):\n",
    "        csim = -1\n",
    "    else:\n",
    "        csim = cosine_similarity(CountVectorizer().fit_transform([pairs_red_us['categories_1'].iloc[i], pairs_red_us['categories_2'].iloc[i]]).toarray())[0][1]\n",
    "    categories_cosines.append(csim)\n",
    "    \n",
    "pairs_red_us['categories_cosines'] = pd.DataFrame(categories_cosines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_red_us.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_final_diffed_us = pairs_red_us[['theta_diff', 'name_cosines', 'full_address_cosines', 'categories_cosines', 'match']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_final_diffed_us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_final_diffed_us['theta_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_final_diffed_us.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_corr = pairs_final_diffed_us.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(pairs_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_final_diffed_us['theta_diff'][pairs_final_diffed_us['match']==True].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_final_diffed_us['theta_diff'][pairs_final_diffed_us['match']==False].describe()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cols_to_scale = ['theta_diff', 'name_cosines', 'full_address_cosines', 'categories_cosines']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_final_diffed_us.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scaler.fit(pairs_final_diffed_us[cols_to_scale])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pairs_final_diffed_us[cols_to_scale] = scaler.transform(pairs_final_diffed_us[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_final_diffed_us.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pairs_corr = pairs_final_diffed_us.corr()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pairs_corr"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.heatmap(pairs_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_final_diffed_us.to_csv(r'C:\\Users\\gorma\\OneDrive\\Documents\\Erdos\\foursquare-location-matching\\tim_code\\working_data\\pairs_final_diffed_us.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_final_diffed_us = pd.read_csv(r'C:\\Users\\gorma\\OneDrive\\Documents\\Erdos\\foursquare-location-matching\\tim_code\\working_data\\pairs_final_diffed_us.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_final_diffed_us = pairs_final_diffed_us.drop('Unnamed: 0', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_final_diffed_us.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_final_diffed_us.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "cols_to_scale = ['theta_diff', 'name_cosines', 'full_address_cosines', 'categories_cosines']\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(pairs_final_diffed_us[cols_to_scale])\n",
    "pairs_final_diffed_us[cols_to_scale] = scaler.transform(pairs_final_diffed_us[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_final_diffed_us.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_final_diffed_us.to_csv(r'C:\\Users\\gorma\\OneDrive\\Documents\\Erdos\\foursquare-location-matching\\tim_code\\working_data\\pairs_final_diffed_us_scaled.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
